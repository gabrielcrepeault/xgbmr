## Mettre à jour le site web pkgdown ####
setwd("../")
pkgdown::build_site()
pkgdown::build_site()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(xgbmr)
library(tidyverse)
library(xgboost)
library(mlr)
library(iml)
library(xtable) # pour des fins de présentation
dt <- SimulatedIndClaims
dat <- dt %>% censoreDataset(evalYr = 2005)
set.seed(20191024) # Même seed que dans presentation-data.Rnw
dat %>%
select(ClNr, AY, starts_with('Pay'), real_ultimate) %>%
sample_n(5) %>%
knitr::kable()
set.seed(20191023)
index <- makeResampleInstance(
desc = makeResampleDesc('Holdout', stratify.cols = 'AY', split = 0.70),
# il faut absolument donner une tâche et un target bidon
task = makeRegrTask(data = dt, target = 'Pay00')
)
traindt <- dat[index$train.inds[[1]],]
testdt <- dat[index$test.inds[[1]],]
mack_bs_tri <- traindt %>%
getAggrTriangle() %>%
ChainLadder::BootChainLadder(R = 1000)
ldf_bs <- mack_bs_tri$simClaims %>%
apply(3, function(triangle){
triangle %>% incr2cum() %>% as.triangle() %>% getLDF()
}) %>% t() %>% apply(2, quantile, probs = 0.8)
data.frame(LDF = ldf_bs) %>% t() %>% knitr::kable()
train_a <- traindt %>%
widetolong() %>%
filter(complete.cases(.)) %>% # garder les années connues
filter(!(Open == 1 & Paid == 0)) %>% # enlever masse à 0
select(-AY, -TotalPaid, -Pay, -still, -max_dev_yr) %>%
rename(Ultimate = real_ultimate) %>%
# Arranger le dataset final pour le modèle A
select(ClNr:RepDel, devYear, Paid, Open, Ultimate) %>%
as_tibble()
train_b <- traindt %>%
widetolong() %>%
filter(complete.cases(.)) %>%
mutate(Ultimate = TotalPaid) %>%
filter(!(Open == 1 & Paid == 0)) %>% # enlever masse à 0
filter(Open == 0) %>%
select(-AY, -TotalPaid, -Pay, -still, -max_dev_yr, -real_ultimate) %>%
as_tibble()
train_c <- traindt %>%
widetolong() %>%
filter(complete.cases(.)) %>% # garder les années connues
mutate(Ultimate = case_when(
still == 1 ~ TotalPaid * ldf_bs[max_dev_yr + 1],
TRUE ~ TotalPaid)) %>%
filter(!(Open == 1 & Paid == 0)) %>% # enlever masse à 0
select(-AY, -TotalPaid, -Pay, -still, -max_dev_yr, -real_ultimate) %>%
as_tibble() # pour enlever le tag grouped df
test <- testdt %>%
widetolong() %>%
filter(complete.cases(.)) %>% # garder les années connues
rename(Ultimate = real_ultimate) %>%
# Arranger le dataset final pour le modèle A
select(ClNr:RepDel, devYear, Paid, Open, Ultimate) %>%
as_tibble()
fit_a$learner$par.vals  %>% data.frame(Modèle = 'A', .) %>%
bind_rows(fit_b$learner$par.vals  %>% data.frame(Modèle = 'B', .),
fit_c$learner$par.vals  %>% data.frame(Modèle = 'C', .)) %>%
knitr::kable()
test_dt <- test %>% select(-ClNr)
test_tsk <- makeRegrTask(data = test_dt, target = 'Ultimate')
pred_a <- predict(fit_a, test_tsk)
pred_b <- predict(fit_b, test_tsk)
pred_c <- predict(fit_c, test_tsk)
test_pred_a <- test_dt %>%
rownames_to_column('id') %>%
mutate_at(vars(id), as.integer) %>%
left_join(pred_a$data, by = "id")
test_pred_b <- test_dt %>%
rownames_to_column('id') %>%
mutate_at(vars(id), as.integer) %>%
left_join(pred_b$data, by = "id")
test_pred_c <- test_dt %>%
rownames_to_column('id') %>%
mutate_at(vars(id), as.integer) %>%
left_join(pred_c$data, by = "id")
## Vraie réserve (selon données simulées du test set)
vraie_reserve <- test_dt %>% summarise(paye = sum(Paid), total = sum(Ultimate), R = total - paye)
## Calcul des réserves totales selon chaque modèle
aa <- apply(bs_pred_a, 2, sum)
bs_res_a <- (aa - sum(test_dt$Paid)) %>% data.frame(A = .)
bb <- apply(bs_pred_b, 2, sum)
bs_res_b <- (bb - sum(test_dt$Paid)) %>% data.frame(B = .)
cc <- apply(bs_pred_c, 2, sum)
bs_res_c <- (cc - sum(test_dt$Paid)) %>% data.frame(C = .)
res_xt <- bind_cols(bs_res_a, bs_res_b, bs_res_c) %>%
gather('Modèle', 'Réserve') %>%
group_by(Modèle) %>%
nest() %>%
mutate(
moyenne = map_dbl(data,function(x) unlist(x) %>%  mean),
sd = map_dbl(data,function(x) unlist(x) %>%  sd),
VaR95 = map_dbl(data,function(x) unlist(x) %>%  quantile(., probs = .95)),
VaR99 = map_dbl(data,function(x) unlist(x) %>%  quantile(., probs = .99))
) %>%
select(-data) %>%
data.frame() %>%
format(big.mark = ' ', justify = 'centre') %>%
knitr::kable()
bind_cols(bs_res_a, bs_res_b, bs_res_c) %>%
gather('Modèle', 'Réserve') %>%
group_by(Modèle) %>%
nest() %>%
mutate(
moyenne = map_dbl(data,function(x) unlist(x) %>%  mean),
sd = map_dbl(data,function(x) unlist(x) %>%  sd),
VaR95 = map_dbl(data,function(x) unlist(x) %>%  quantile(., probs = .95)),
VaR99 = map_dbl(data,function(x) unlist(x) %>%  quantile(., probs = .99))
) %>%
select(-data) %>%
data.frame() %>%
format(big.mark = ' ', justify = 'centre') %>%
knitr::kable()
bind_cols(bs_res_a, bs_res_b, bs_res_c) %>%
ggplot() +
geom_density(aes(x = A, y = ..density..,  fill = 'A'), n = 2^12, alpha = 0.4) +
geom_density(aes(x = B, y = ..density.., fill = 'B'), n = 2^12, alpha = 0.4) +
geom_density(aes(x = C, y = ..density.., fill = 'C'), n = 2^12, alpha = 0.4) +
theme_classic() +
theme(legend.position = 'bottom') +
labs(fill = 'Modèles', x = 'Réserve totale', y = 'Probabilité') +
geom_vline(xintercept = vraie_reserve$R, linetype = 'dashed')
pkgdown::build_site()
pkgdown::build_site()
library(xgbmr)
library(xgbmr)
#' - "truth" : la vraie valeur à prédire
#' - "response" : valeur prédite
#' - "var" : la variable explicative qu'on veut illustrer sur le graphique.
#'
#' @param var Nom de la variable (avec syntaxe tidyverse) qu'on veut grouper
#' @param show.table Possbilité de print le data.frame aggrégé (qui présente le nombre
#' d'observation et le RMSE moyen) qui a servi à produire le graphique.
#'
#'
#' @export
rmse_selon_variable <- function(pred, var, show.table = F){
var <- enquo(var)
data <- pred %>%
group_by(!!var) %>%
summarise(
rmse = sqrt(mean((truth - response)^2)),
nobs = n()
)
if (show.table) print(data)
## Output le ggplot des RMSE avec la fréquence de chaque variable
rmse_global <- sqrt(mean((pred$truth - pred$response)^2))
data %>%
ggplot(aes(x = !!var)) +
geom_point(aes(geom = rmse)) +
geom_bar(aes(y = nobs,
fill = paste0("Nombre d'observations totale par ",
rlang::as_name(var))
),
stat = 'identity', alpha = .2) +
geom_hline(aes(col = 'RMSE global', yintercept = rmse_global)) +
theme(legend.position = 'bottom', legend.direction = 'vertical') +
labs(fill = NULL, col = NULL, y = "RMSE", geom='RMSE')
}
data %>%
ggplot(aes(x = !!var)) +
geom_point(aes(geom = rmse)) +
geom_bar(aes(y = nobs,
fill = paste0("Nombre d'observations totale par ",
rlang::as_name(var))
),
stat = 'identity', alpha = .2) +
geom_hline(aes(col = 'RMSE global', yintercept = rmse_global)) +
theme(legend.position = 'bottom', legend.direction = 'vertical') +
labs(fill = NULL, col = NULL, y = "RMSE")
require(tidyverse)
#' - "truth" : la vraie valeur à prédire
#' - "response" : valeur prédite
#' - "var" : la variable explicative qu'on veut illustrer sur le graphique.
#'
#' @param var Nom de la variable (avec syntaxe tidyverse) qu'on veut grouper
#' @param show.table Possbilité de print le data.frame aggrégé (qui présente le nombre
#' d'observation et le RMSE moyen) qui a servi à produire le graphique.
#'
#'
#' @export
rmse_selon_variable <- function(pred, var, show.table = F){
require(tidyverse)
var <- enquo(var)
data <- pred %>%
group_by(!!var) %>%
summarise(
rmse = sqrt(mean((truth - response)^2)),
nobs = n()
)
if (show.table) print(data)
## Output le ggplot des RMSE avec la fréquence de chaque variable
rmse_global <- sqrt(mean((pred$truth - pred$response)^2))
data %>%
ggplot(aes(x = !!var)) +
geom_point(aes(geom = rmse)) +
geom_bar(aes(y = nobs,
fill = paste0("Nombre d'observations totale par ",
rlang::as_name(var))
),
stat = 'identity', alpha = .2) +
geom_hline(aes(col = 'RMSE global', yintercept = rmse_global)) +
theme(legend.position = 'bottom', legend.direction = 'vertical') +
labs(fill = NULL, col = NULL, y = "RMSE")
}
data %>%
ggplot(aes(x = !!var)) +
geom_point(aes(y = rmse)) +
geom_bar(aes(y = nobs,
fill = paste0("Nombre d'observations totale par ",
rlang::as_name(var))
),
stat = 'identity', alpha = .2) +
geom_hline(aes(col = 'RMSE global', yintercept = rmse_global)) +
theme(legend.position = 'bottom', legend.direction = 'vertical') +
labs(fill = NULL, col = NULL, y = "RMSE", geom = 'RMSE')
#' - "truth" : la vraie valeur à prédire
#' - "response" : valeur prédite
#' - "var" : la variable explicative qu'on veut illustrer sur le graphique.
#'
#' @param var Nom de la variable (avec syntaxe tidyverse) qu'on veut grouper
#' @param show.table Possbilité de print le data.frame aggrégé (qui présente le nombre
#' d'observation et le RMSE moyen) qui a servi à produire le graphique.
#'
#'
#' @export
rmse_selon_variable <- function(pred, var, show.table = F){
require(tidyverse)
var <- enquo(var)
data <- pred %>%
group_by(!!var) %>%
summarise(
rmse = sqrt(mean((truth - response)^2)),
nobs = n()
)
if (show.table) print(data)
## Output le ggplot des RMSE avec la fréquence de chaque variable
rmse_global <- sqrt(mean((pred$truth - pred$response)^2))
data %>%
ggplot(aes(x = !!var)) +
geom_point(aes(y = rmse)) +
geom_bar(aes(y = nobs,
fill = paste0("Nombre d'observations totale par ",
rlang::as_name(var))
),
stat = 'identity', alpha = .2) +
geom_hline(aes(col = 'RMSE global', yintercept = rmse_global)) +
theme(legend.position = 'bottom', legend.direction = 'vertical') +
labs(fill = NULL, col = NULL, y = "RMSE", geom = 'RMSE')
}
#' - "truth" : la vraie valeur à prédire
#' - "response" : valeur prédite
#' - "var" : la variable explicative qu'on veut illustrer sur le graphique.
#'
#' @param var Nom de la variable (avec syntaxe tidyverse) qu'on veut grouper
#' @param show.table Possbilité de print le data.frame aggrégé (qui présente le nombre
#' d'observation et le RMSE moyen) qui a servi à produire le graphique.
#'
#'
#' @export
rmse_selon_variable <- function(pred, var, show.table = F){
require(tidyverse)
var <- enquo(var)
data <- pred %>%
group_by(!!var) %>%
summarise(
rmse = sqrt(mean((truth - response)^2)),
nobs = n()
)
if (show.table) print(data)
## Output le ggplot des RMSE avec la fréquence de chaque variable
rmse_global <- sqrt(mean((pred$truth - pred$response)^2))
data %>%
ggplot(aes(x = !!var)) +
geom_point(aes(y = rmse)) +
geom_bar(aes(y = nobs,
fill = paste0("Nombre d'observations totale par ",
rlang::as_name(var))
),
stat = 'identity', alpha = .2) +
geom_hline(aes(col = 'RMSE global', yintercept = rmse_global)) +
theme(legend.position = 'bottom', legend.direction = 'vertical') +
labs(fill = NULL, col = NULL, y = "RMSE", geom = 'RMSE')
}
#' - "truth" : la vraie valeur à prédire
#' - "response" : valeur prédite
#' - "var" : la variable explicative qu'on veut illustrer sur le graphique.
#'
#' @param var Nom de la variable (avec syntaxe tidyverse) qu'on veut grouper
#' @param show.table Possbilité de print le data.frame aggrégé (qui présente le nombre
#' d'observation et le RMSE moyen) qui a servi à produire le graphique.
#'
#'
#' @export
rmse_selon_variable <- function(pred, var, show.table = F){
require(tidyverse)
var <- enquo(var)
data <- pred %>%
group_by(!!var) %>%
summarise(
rmse = sqrt(mean((truth - response)^2)),
nobs = n()
)
if (show.table) print(data)
## Output le ggplot des RMSE avec la fréquence de chaque variable
rmse_global <- sqrt(mean((pred$truth - pred$response)^2))
data %>%
ggplot(aes(x = !!var)) +
geom_point(aes(y = rmse)) +
geom_bar(aes(y = nobs,
fill = paste0("Nombre d'observations totale par ",
rlang::as_name(var))
),
stat = 'identity', alpha = .2) +
geom_hline(aes(col = 'RMSE global', yintercept = rmse_global)) +
theme(legend.position = 'bottom', legend.direction = 'vertical') +
labs(fill = NULL, col = NULL, y = "RMSE")
}
library(xgbmr)
pkgdown::build_site()
## ******************************************
## Gabriel Crépeault-Cauchon
## Fichier clean pour parameter tuning en utilisant seulement mlr
## 6 novembre 2019
## Attention : ce programme prend énormément de temps à rouler
## Selon le modèle qu'on veut rouler (modèle A, B ou C), certains éléments
## à mettre en commentaire
## ******************************************
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
## ******************************************
## Gabriel Crépeault-Cauchon
## Fichier clean pour parameter tuning en utilisant seulement mlr
## 6 novembre 2019
## Attention : ce programme prend énormément de temps à rouler
## Selon le modèle qu'on veut rouler (modèle A, B ou C), certains éléments
## à mettre en commentaire
## ******************************************
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))
## Import data and functions
library(mlr)
library(tidyverse)
library(xgboost)
library(xgbmr)
## Certains paramètres. Le contenu de ce script aurait pu être mis dans un fct
max_nrounds <- 100
model_name <- "modele_a_test"
set.seed(2019)
setup_training_env
## Créer un sous-dossier pour stocker l'info par rapport à ce modèle
xgbmr::setup_training_env(model_name = model_name)
## Importer jeu de données d'entrainement (et créer la tâche mlr)
# traindt <- read.csv('../data/train_a.csv') %>% select(-ClNr) # modèle A
# traindt <- read.csv('../data/train_b.csv') %>% select(-ClNr) # modèle B
traindt <- read.csv('../data/train_c.csv') %>% select(-ClNr) # modèle C
train_tsk <- makeRegrTask(data = traindt, target = 'Ultimate')
## Fixer les paramètres initiaux de xgboost
xgb_pars <- list(
objective="reg:squarederror",
eval_metric = 'rmse',
eta = 0.1,
max_depth = 1,
min_child_weight = 5,
gamma = 1,
verbose = 0,
subsample = 0.5,
colsample_bytree = 0.5,
alpha = 1,
lambda = 1
)
## Initialiser le premier learner
lrn_init <- makeLearner(cl = 'regr.xgboost', id = "xgb_initial", par.vals = xgb_pars)
## First : Tune nrounds avec eta=0.1 ####
tuner1 <- tune_nrounds(learner = lrn_init, task = train_tsk,
root = root, iters = max_nrounds)
library(xgbmr)
root <- 'models'
## Certains paramètres. Le contenu de ce script aurait pu être mis dans un fct
max_nrounds <- 10
## Fixer les paramètres initiaux de xgboost
xgb_pars <- list(
objective="reg:squarederror",
eval_metric = 'rmse',
eta = 0.1,
max_depth = 1,
min_child_weight = 5,
gamma = 1,
verbose = 0,
subsample = 0.5,
colsample_bytree = 0.5,
alpha = 1,
lambda = 1
)
## Initialiser le premier learner
lrn_init <- makeLearner(cl = 'regr.xgboost', id = "xgb_initial", par.vals = xgb_pars)
## First : Tune nrounds avec eta=0.1 ####
tuner1 <- tune_nrounds(learner = lrn_init, task = train_tsk,
root = root, iters = max_nrounds)
## Certains paramètres. Le contenu de ce script aurait pu être mis dans un fct
max_nrounds <- 1
root <- file.path('models', model_name)
root
set.seed(2019)
## Créer un sous-dossier pour stocker l'info par rapport à ce modèle
xgbmr::setup_training_env(model_name = model_name)
## Importer jeu de données d'entrainement (et créer la tâche mlr)
# traindt <- read.csv('../data/train_a.csv') %>% select(-ClNr) # modèle A
# traindt <- read.csv('../data/train_b.csv') %>% select(-ClNr) # modèle B
traindt <- read.csv('../data/train_c.csv') %>% select(-ClNr) # modèle C
train_tsk <- makeRegrTask(data = traindt, target = 'Ultimate')
## Fixer les paramètres initiaux de xgboost
xgb_pars <- list(
objective="reg:squarederror",
eval_metric = 'rmse',
eta = 0.1,
max_depth = 1,
min_child_weight = 5,
gamma = 1,
verbose = 0,
subsample = 0.5,
colsample_bytree = 0.5,
alpha = 1,
lambda = 1
)
## Initialiser le premier learner
lrn_init <- makeLearner(cl = 'regr.xgboost', id = "xgb_initial", par.vals = xgb_pars)
## First : Tune nrounds avec eta=0.1 ####
tuner1 <- tune_nrounds(learner = lrn_init, task = train_tsk,
root = root, iters = max_nrounds)
## Certains paramètres. Le contenu de ce script aurait pu être mis dans un fct
max_nrounds <- 10
model_name <- "modele_a_test"
root <- file.path('models', model_name)
set.seed(2019)
## Créer un sous-dossier pour stocker l'info par rapport à ce modèle
xgbmr::setup_training_env(model_name = model_name)
## Importer jeu de données d'entrainement (et créer la tâche mlr)
# traindt <- read.csv('../data/train_a.csv') %>% select(-ClNr) # modèle A
# traindt <- read.csv('../data/train_b.csv') %>% select(-ClNr) # modèle B
traindt <- read.csv('../data/train_c.csv') %>% select(-ClNr) # modèle C
train_tsk <- makeRegrTask(data = traindt, target = 'Ultimate')
## Fixer les paramètres initiaux de xgboost
xgb_pars <- list(
objective="reg:squarederror",
eval_metric = 'rmse',
eta = 0.1,
max_depth = 1,
min_child_weight = 5,
gamma = 1,
verbose = 0,
subsample = 0.5,
colsample_bytree = 0.5,
alpha = 1,
lambda = 1
)
## Initialiser le premier learner
lrn_init <- makeLearner(cl = 'regr.xgboost', id = "xgb_initial", par.vals = xgb_pars)
## First : Tune nrounds avec eta=0.1 ####
tuner1 <- tune_nrounds(learner = lrn_init, task = train_tsk,
root = root, iters = max_nrounds)
lrn1 <- tuner1$updated_learner
## Tune max_depth ####
tuner2 <- tune_and_update(learner = lrn1, task = train_tsk,
param_set = makeParamSet(makeDiscreteParam('max_depth', values = c(1:6))),
show.info = T, root = root)
lrn2 <- tuner2$updated_learner
## Tune gamma ####
tuner3 <- tune_and_update(learner = lrn2, task = train_tsk,
param_set = makeParamSet(makeDiscreteParam('gamma', values = c(.1, 1, 5, 10, 25))),
show.info = T, root = root)
lrn3 <- tuner3$updated_learner
## Tune min_child_weight ####
tuner4 <- tune_and_update(learner = lrn3, task = train_tsk,
param_set = makeParamSet(makeDiscreteParam('min_child_weight', values = c(5, 10, 20, 30, 50, 100))),
show.info = T, root = root)
lrn4 <- tuner4$updated_learner
## Second : Réajuster nrounds avant de continuer le tuning ####
tuner5 <- tune_nrounds(learner = lrn4, task = train_tsk,
root = root, iters = max_nrounds)
lrn5 <- tuner5$updated_learner
## Tune colsample_bytree ####
tuner6 <- tune_and_update(lrn5, task = train_tsk,
param_set = makeParamSet(
makeDiscreteParam('colsample_bytree', values = c(.1, .25, .5, .75, .9))
), show.info = T, root = root)
lrn6 <- tuner6$updated_learner
## Tune subsample ####
tuner7 <- tune_and_update(lrn6, task = train_tsk,
param_set = makeParamSet(
makeDiscreteParam('subsample', values = c(.1, .25, .5, .75, .9))
), show.info = T, root = root)
## Tune gamma ####
tuner3 <- tune_and_update(learner = lrn2, task = train_tsk,
param_set = makeParamSet(makeDiscreteParam('gamma', values = c(.1, 1, 5, 10, 25))),
show.info = T, root = root) %>%
tune_and_update(learner = .$updated_learner, task = train_tsk,
param_set = makeParamSet(makeDiscreteParam('min_child_weight', values = c(5, 10, 20, 30, 50, 100))),
show.info = T, root = root)
